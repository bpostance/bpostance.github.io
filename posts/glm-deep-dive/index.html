<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="A deep dive on GLM’s in frequency severity models" /><meta name="author" content="Ben Postance" /><meta property="og:locale" content="en_US" /><meta name="description" content="Risk, Data Science and Machine Learning" /><meta property="og:description" content="Risk, Data Science and Machine Learning" /><link rel="canonical" href="https://bpostance.github.io/posts/glm-deep-dive/" /><meta property="og:url" content="https://bpostance.github.io/posts/glm-deep-dive/" /><meta property="og:site_name" content="Ben Postance" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-05-17T19:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="A deep dive on GLM’s in frequency severity models" /><meta name="twitter:site" content="@benpostance" /><meta name="twitter:creator" content="@Ben Postance" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Ben Postance"},"dateModified":"2021-04-19T20:43:27+01:00","datePublished":"2020-05-17T19:00:00+01:00","description":"Risk, Data Science and Machine Learning","headline":"A deep dive on GLM’s in frequency severity models","mainEntityOfPage":{"@type":"WebPage","@id":"https://bpostance.github.io/posts/glm-deep-dive/"},"url":"https://bpostance.github.io/posts/glm-deep-dive/"}</script><title>A deep dive on GLM's in frequency severity models | Ben Postance</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> // see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> MathJax = { tex: { inlineMath: [ // start/end delimiter pairs for in-line math ['$','$'], ['\\(','\\)'] ], displayMath: [ // start/end delimiter pairs for display math ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-140894462-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-140894462-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="top"></div><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/7165735?s=460&u=7ca34b8152bbff087bfc860cc87a4c35b4f9cb1b&v=4" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Ben Postance</a></div><div class="site-subtitle font-italic">Risk, Data Science and Machine Learning</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT ME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/bpostance" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/benpostance" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['benpostance','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>A deep dive on GLM's in frequency severity models</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>A deep dive on GLM's in frequency severity models</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Ben Postance </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, May 17, 2020, 7:00 PM +0100" prep="on" > May 17, 2020 <i class="unloaded">2020-05-17T19:00:00+01:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Apr 19, 2021, 8:43 PM +0100" prefix="Updated " > Apr 19, 2021 <i class="unloaded">2021-04-19T20:43:27+01:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3503 words">19 min</span></div></div><div class="post-content"><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig1.png" alt="drawing" width="800" height="350" /></p><p><strong><a href="https://github.com/bpostance/dsc.learn/blob/main/Risk/02-GLM-FrequencySeverity-model.ipynb">Jupyter notebook here</a></strong></p><p>This notebook is a deep dive into <a href="https://online.stat.psu.edu/stat504/node/216/">General Linear Models (GLM’s)</a> with a focus on the GLM’s used in insurance risk modeling and pricing (Yan, J. 2010).I have used GLM’s before including: a Logistic Regression for landslide geo-hazards (Postance, 2017), for modeling extreme rainfall and developing catastrophe models (Postance, 2017). The motivation for this post is to develop a deeper knowledge of the assumptions and application of the models and methods used by Insurance Actuaries, and to better understand how these compare to machine learning methods.</p><h3 id="case-study-dataset-motorcylce-insurance">Case study dataset: motorcylce insurance</h3><p>The <a href="https://cran.r-project.org/web/packages/insuranceData/insuranceData.pdf#Rfn.dataOhlsson.1">Ohlsson dataset</a> is from a former Swedish insurance company Wasa. The data includes aggregated customer, policy and claims data for 64,548 motorcycle coverages for the period 1994-1998. The data is used extensively in actuarial training and syllabus worldwide <a href="https://www.springer.com/gp/book/9783642107900#aboutBook">Ohlsson, (2010)</a>.</p><p>Variables include:</p><ul><li><em>data available <a href="https://staff.math.su.se/esbj/GLMbook/case.html">here</a></em></ul><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>dtype<th>null<th>nunique<tbody><tr><td>Age<td>float64<td>0<td>85<tr><td>Sex<td>category<td>0<td>2<tr><td>Geog<td>category<td>0<td>7<tr><td>EV<td>category<td>0<td>7<tr><td>VehAge<td>int64<td>0<td>85<tr><td>NCD<td>category<td>0<td>7<tr><td>PYrs<td>float64<td>0<td>2577<tr><td>Claims<td>int64<td>0<td>3<tr><td>Severity<td>float64<td>0<td>590<tr><td>Claim<td>int64<td>0<td>2<tr><td>SeverityAvg<td>float64<td>0<td>590</table></div><h3 id="eda">EDA</h3><p>All data: low number of claims and frequency (1% freq)</p><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>VehAge<th>PYrs<th>Claims<th>Severity<th>Claim<th>SeverityAvg<tbody><tr><td>count<td>64548.000000<td>64548.000000<td>64548.000000<td>64548.000000<td>64548.000000<td>64548.000000<td>64548.000000<tr><td>mean<td>42.416062<td>12.540063<td>1.010759<td>0.010798<td>264.017785<td>0.010380<td>246.964360<tr><td>std<td>12.980960<td>9.727445<td>1.307356<td>0.107323<td>4694.693604<td>0.101352<td>4198.994975<tr><td>min<td>0.000000<td>0.000000<td>0.002740<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><td>25%<td>31.000000<td>5.000000<td>0.463014<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><td>50%<td>44.000000<td>12.000000<td>0.827397<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><td>75%<td>52.000000<td>16.000000<td>1.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><td>max<td>92.000000<td>99.000000<td>31.339730<td>2.000000<td>365347.000000<td>1.000000<td>211254.000000</table></div><p>Claims data:</p><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>VehAge<th>PYrs<th>Claims<th>Severity<th>Claim<th>SeverityAvg<tbody><tr><td>count<td>670.000000<td>670.000000<td>670.000000<td>670.000000<td>670.000000<td>670.0<td>670.000000<tr><td>mean<td>35.476119<td>7.965672<td>1.579415<td>1.040299<td>25435.552239<td>1.0<td>23792.620149<tr><td>std<td>12.851056<td>6.768896<td>2.983317<td>0.196805<td>38539.415033<td>0.0<td>33765.250000<tr><td>min<td>16.000000<td>0.000000<td>0.002740<td>1.000000<td>16.000000<td>1.0<td>16.000000<tr><td>25%<td>25.000000<td>2.000000<td>0.430137<td>1.000000<td>3031.500000<td>1.0<td>3007.750000<tr><td>50%<td>30.000000<td>7.000000<td>0.790411<td>1.000000<td>9015.000000<td>1.0<td>8723.500000<tr><td>75%<td>47.000000<td>12.000000<td>1.497945<td>1.000000<td>29304.500000<td>1.0<td>26787.750000<tr><td>max<td>68.000000<td>55.000000<td>31.167120<td>2.000000<td>365347.000000<td>1.0<td>211254.000000</table></div><p>Claims and losses by each variable:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig7_0.png" alt="png" /></p><h3 id="modeling">Modeling</h3><p><strong><em>Train-Test split</em></strong></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="c1"># train-test splits stratifies on claims
# take copies to overcome chained assignment
</span><span class="n">train</span><span class="p">,</span><span class="n">test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1990</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">])</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="p">.</span><span class="n">index</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Severity</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Severity</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Frequency</span><span class="se">\n</span><span class="s">Train:</span><span class="se">\t</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="se">\t</span><span class="s">$</span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="se">\n</span><span class="s">Test:</span><span class="se">\t</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="se">\t</span><span class="s">$</span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># severity train test
</span><span class="n">train_severity</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">test_severity</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">train_severity</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">train_severity</span><span class="p">[</span><span class="sh">'</span><span class="s">Severity</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">test_severity</span><span class="p">[</span><span class="sh">'</span><span class="s">Claim</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">(),</span><span class="n">test_severity</span><span class="p">[</span><span class="sh">'</span><span class="s">Severity</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Severity</span><span class="se">\n</span><span class="s">Train:</span><span class="se">\t</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_severity</span><span class="p">)</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="se">\t</span><span class="s">$</span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="se">\n</span><span class="s">Test:</span><span class="se">\t</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_severity</span><span class="p">)</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="se">\t</span><span class="s">$</span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Frequency
Train:	45183	469	$11664342.0
Test:	19365	201	$5377478.0

Severity
Train:	469	469	$11664342.0
Test:	201	201	$5377478.0
</pre></table></code></div></div><h3 id="claim-frequency"><em>Claim Frequency</em></h3><p>For predicting the occurrence of a single claim (i.e. binary classification) one can use the Binomial distribution (a.k.a Bernoulli trial or coin-toss experiment).</p><p>When predicting claim counts or frequency, $Y$, a model that produces Poisson distributed outputs is required. For instance, a Poisson model is suitable for estimating the number of insurance claims per policy per year, or to estimate the number of car crashes per month.</p><p>The key components and assumptions of a Poisson distributed process are:</p><ol><li>event occurrence is independent of other events.<li>events occur within a fixed period of time.<li>the mean a variance of the distribution are equal e.g. $mu(X) = Var(X) = λ$</ol><p><a href="https://online.stat.psu.edu/stat504/node/57/"><em>STAT 504: Poisson Distribution</em></a></p><p>If the mean and variance are unequal the distribution is said to be over-dispersed (var &gt; mean) or under-dispersed (var &lt; mean). Over-dispersion commonly arises in data where there are large number of zero’s (a.k.a <a href="https://en.wikipedia.org/wiki/Zero-inflated_model">zero-inflated</a>).</p><p>In the case of zero-inflated data, it is “<em>A sound practice is to estimate both Poisson and negative binomial models.</em>” <a href="http://faculty.econ.ucdavis.edu/faculty/cameron/racd2/"><em>Cameron, 2013</em></a>. Also see this practical example for <a href="https://dius.com.au/2017/08/03/using-statsmodels-glms-to-model-beverage-consumption/">beverage consumption in pdummy_xyhon</a></p><p>In GLM’s, link-functions are applied in order to make the mean outcome (prediction) fit to some linear model of input variables from other distributions. “<em>A natural fit for count variables that follow the Poisson or negative binomial distribution is the log link. The log link exponentiates the linear predictors. It does not log transform the outcome variable.</em>” - <a href="https://www.theanalysisfactor.com/count-models-understanding-the-log-link-function/"><em>Count Models: Understanding the Log Link Function,TAF</em></a></p><p>For more information on link-functions see also <a href="https://bookdown.org/castillo_sam_d/Exam-PA-Study-Manual/glms-for-classification.html#link-functions">here</a>.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://i0.wp.com/www.theanalysisfactor.com/wp-content/uploads/2016/12/StataCombos-CM2-Blog-JM.png?w=535&amp;ssl=1" alt="link functions" /></p><p>Lastly, for any form of count prediction model one can also set an offset or exposure. An offset, if it is known, is applied in order to account for the relative differences in exposure time for of a set of inputs. For example, in insurance claims we might expect to see more claims on an account with 20 years worth of annual policies compared to an account with a single policy year. Offsets account for the relative exposure, surface area, population size, etc and is akin to the relative frequency of occurrence (<em>Claims/years</em>). See these intuitive SO answers <a href="https://stats.stackexchange.com/questions/232666/should-i-use-an-offset-for-my-poisson-glm">here</a>, <a href="https://github.com/statsmodels/statsmodels/issues/1486#issuecomment-40945831">here</a>, and <a href="https://stats.stackexchange.com/questions/25415/using-offset-in-binomial-model-to-account-for-increased-numbers-of-patients">here</a>.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># Mean &amp; Variance
</span><span class="n">mu</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">Claims</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">var</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">([</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">Claims</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">mu =  </span><span class="si">{</span><span class="n">mu</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">var = </span><span class="si">{</span><span class="n">var</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>mu =  0.0108
var = 0.0115
</pre></table></code></div></div><p>Here we observe an over-dispersed zero-inflated case as the variance of claim occurrence ($v=0.0115$) exceeds its mean ($mu=0.0108$).</p><p>As suggested in Cameron (2013) we should therefore try both $Poisson$ and $Negative Binomial$ distributions.</p><p>For good measure, and to illustrate its relationship, lets also include a $Binomial$ distribution model. The Binomial model with a logit link is equivalent to a binary Logistic Regression model [<a href="https://www.researchgate.net/post/what_is_the_difference_between_running_a_binary_logistic_regression_and_generalised_linear_model">a</a>,<a href="https://towardsdatascience.com/the-binomial-regression-model-everything-you-need-to-know-5216f1a483d3">b</a>]. Modeling A binary outcome is not a totally unreasonable approach in this case given that the number of accounts with claims $n&gt;1$ is low (22) and as the $Binomial$ distribution extends to a $Poisson$ when trials $N&gt;20$ is high and $p&lt;0.05$ is low (see <a href="https://en.wikipedia.org/wiki/Poisson_distribution#Related_distributions">wiki</a>, <a href="https://math.stackexchange.com/questions/1050184/difference-between-poisson-and-binomial-distributions">here</a> and <a href="https://www.itl.nist.gov/div898/handbook/pmc/section3/pmc331.htm">here</a>).</p><p>However, there is one change we need to make with the Binomial model. That is to alter the way we handle exposure. A few hours of research on the matter led me down the rabbit hole of conflicting ideas in textbooks, papers [<a href="https://doi.org/10.1093/ije/dyu029">i</a>] and debates on CrossValidated [<a href="https://stats.stackexchange.com/questions/246318/difference-between-offset-and-weights">a</a>,<a href="https://stats.stackexchange.com/questions/25415/using-offset-in-binomial-model-to-account-for-increased-numbers-of-patients/35478">b</a>]. In contrast to Poisson and neg binomial there is no way to add a constant term or offset in the binomial formulation <a href="https://stats.stackexchange.com/a/35478/100439">(see here)</a>. Rather it is appropriate to either: <a href="https://stats.stackexchange.com/a/35436/100439">include the exposure as a predictor variable</a>, or to use weights for each observation (see <a href="https://stackoverflow.com/a/62798889/4538066">here</a> and the <a href="https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html#statsmodels.genmod.generalized_linear_model.GLM">statsmodels guidance on methods for GLM with weights and observed frequencies</a>. I opted for the weighted GLM. The model output of the binomial GLM is the probability of at least 1 claim occurring weighted by the observation time $t=Pyrs$. Note there is no equivalent setting on the predict side, the predictions assume a discrete equivalent time exposure t=1.</p><p>In addition it is common in insurance risk models to use a <a href="https://towardsdatascience.com/an-illustrated-guide-to-the-zero-inflated-poisson-model-b22833343057">quasi-poisson or zero inflated Poisson (ZIP)</a> model in scenarios with high instances of zero claims. In data science and machine learning we would refer to this as an unbalanced learning problem (see bootstrap, cross validation, SMOTE). The ZIP model combines:</p><ul><li>a binomial model to determine the likelihood of one or more claims occurring (0/1)<li>a negative binomial or poisson to estimate the number of claims (0…n)<li>a severity model to estimate the avg size of each claim (1…n)</ul><p>Statsmodels uses patsy <a href="https://www.statsmodels.org/devel/example_formulas.html">formula notation</a>. This includes: <a href="https://www.statsmodels.org/devel/contrasts.html">notation for categorical variables </a>, setting <a href="https://stackoverflow.com/a/22439820/4538066">reference/base levels</a>, <a href="https://www.statsmodels.org/devel/contrasts.html">encoding options</a>, and <a href="https://www.statsmodels.org/devel/example_formulas.html#categorical-variables">operators</a>.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="c1"># # examples of formula notation in smf
# print(' + '.join(train.columns))
# expr = "Claims ~ Age+C(Sex)+C(Geog, Treatment(reference=3))+EV+VehAge+NCD"
</span>
<span class="c1"># including PYrs as parameter commented out in glm()
</span><span class="n">expr</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Claims ~ Age + Sex + Geog + EV + VehAge + NCD</span><span class="sh">"</span> <span class="c1"># + np.log(PYrs)
</span>
<span class="n">FreqPoisson</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">expr</span><span class="p">,</span>
                      <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                      <span class="n">offset</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">PYrs</span><span class="sh">'</span><span class="p">]),</span>
                      <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">Poisson</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">log</span><span class="p">())).</span><span class="nf">fit</span><span class="p">()</span>

<span class="n">FreqNegBin</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">expr</span><span class="p">,</span>
                      <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                      <span class="n">offset</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">PYrs</span><span class="sh">'</span><span class="p">]),</span>
                      <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">NegativeBinomial</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">log</span><span class="p">())).</span><span class="nf">fit</span><span class="p">()</span>

<span class="c1"># uses the binary "Claim" field as target
# offset is Pyrs (Years complete 0.0...n)
# aka a binary logistic regression
</span><span class="n">FreqBinom</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="sh">"</span><span class="s">Claim ~ Age + Sex + Geog + EV + VehAge + NCD </span><span class="sh">"</span> <span class="p">,</span>
                    <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                    <span class="n">freq_weights</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">PYrs</span><span class="sh">'</span><span class="p">],</span>
                    <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">Binomial</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">logit</span><span class="p">())).</span><span class="nf">fit</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="model-coefficients">Model coefficients</h3><p><strong><em>Poisson Parameters</em></strong></p><ul><li><a href="https://stackoverflow.com/questions/14923684/interpreting-the-output-of-glm-for-poisson-regression">Poisson GLM params</a><li><a href="https://stackoverflow.com/questions/25828184/fitting-to-poisson-histogram">Find lambda</a></ul><p>We can derive the model output using predict or the raw coefficients. Sampling the Poisson rate (<em>lambda</em>) illustrates the difference in predicted rates for the intercept and for a when a driver is male.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">FreqPoisson</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</pre></table></code></div></div><table class="simpletable"><caption>Generalized Linear Model Regression Results<tr><th>Dep. Variable:<td>Claims<th> No. Observations:<td> 45183<tr><th>Model:<td>GLM<th> Df Residuals:<td> 45161<tr><th>Model Family:<td>Poisson<th> Df Model:<td> 21<tr><th>Link Function:<td>log<th> Scale:<td> 1.0000<tr><th>Method:<td>IRLS<th> Log-Likelihood:<td> -2541.7<tr><th>Date:<td>Wed, 14 Oct 2020<th> Deviance:<td> 4135.6<tr><th>Time:<td>21:43:22<th> Pearson chi2:<td>1.83e+05<tr><th>No. Iterations:<td>22<th><td><tr><th>Covariance Type:<td>nonrobust<th><td></table><table class="simpletable"><tr><td><th>coef<th>std err<th>z<th>P&gt;|z|<th>[0.025<th>0.975]<tr><th>Intercept<td> -0.9052<td> 0.284<td> -3.184<td> 0.001<td> -1.462<td> -0.348<tr><th>Sex[T.M]<td> 0.3881<td> 0.162<td> 2.392<td> 0.017<td> 0.070<td> 0.706<tr><th>Geog[T.2]<td> -0.6478<td> 0.135<td> -4.811<td> 0.000<td> -0.912<td> -0.384<tr><th>Geog[T.3]<td> -0.9043<td> 0.137<td> -6.606<td> 0.000<td> -1.173<td> -0.636<tr><th>Geog[T.4]<td> -1.3826<td> 0.123<td> -11.254<td> 0.000<td> -1.623<td> -1.142<tr><th>Geog[T.5]<td> -1.5218<td> 0.389<td> -3.912<td> 0.000<td> -2.284<td> -0.759<tr><th>Geog[T.6]<td> -1.4581<td> 0.315<td> -4.623<td> 0.000<td> -2.076<td> -0.840<tr><th>Geog[T.7]<td> -22.0308<td> 1.77e+04<td> -0.001<td> 0.999<td>-3.47e+04<td> 3.46e+04<tr><th>EV[T.2]<td> 0.0923<td> 0.237<td> 0.389<td> 0.697<td> -0.372<td> 0.557<tr><th>EV[T.3]<td> -0.4219<td> 0.199<td> -2.115<td> 0.034<td> -0.813<td> -0.031<tr><th>EV[T.4]<td> -0.3602<td> 0.215<td> -1.678<td> 0.093<td> -0.781<td> 0.061<tr><th>EV[T.5]<td> -0.0334<td> 0.204<td> -0.164<td> 0.870<td> -0.433<td> 0.367<tr><th>EV[T.6]<td> 0.4132<td> 0.202<td> 2.042<td> 0.041<td> 0.017<td> 0.810<tr><th>EV[T.7]<td> 0.3316<td> 0.483<td> 0.687<td> 0.492<td> -0.614<td> 1.278<tr><th>NCD[T.2]<td> -0.1441<td> 0.181<td> -0.795<td> 0.426<td> -0.499<td> 0.211<tr><th>NCD[T.3]<td> 0.0184<td> 0.192<td> 0.096<td> 0.923<td> -0.357<td> 0.394<tr><th>NCD[T.4]<td> 0.3047<td> 0.184<td> 1.660<td> 0.097<td> -0.055<td> 0.664<tr><th>NCD[T.5]<td> -0.0535<td> 0.215<td> -0.249<td> 0.804<td> -0.475<td> 0.368<tr><th>NCD[T.6]<td> 0.0967<td> 0.206<td> 0.470<td> 0.639<td> -0.307<td> 0.501<tr><th>NCD[T.7]<td> 0.1835<td> 0.137<td> 1.334<td> 0.182<td> -0.086<td> 0.453<tr><th>Age<td> -0.0580<td> 0.004<td> -13.633<td> 0.000<td> -0.066<td> -0.050<tr><th>VehAge<td> -0.0762<td> 0.008<td> -9.781<td> 0.000<td> -0.091<td> -0.061</table><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Lambda intercept: 0.40
Lambda intercept + male: 0.60
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig18_1.png" alt="png" /></p><p><strong><em>Negative binomial coefficients and incidence rate ratio</em></strong></p><ul><li>https://stats.idre.ucla.edu/stata/dae/negative-binomial-regression/<li>https://stats.stackexchange.com/questions/17006/interpretation-of-incidence-rate-ratios<li>https://stats.stackexchange.com/questions/414752/how-to-interpret-incidence-rate-ratio<li>https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section5.html</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">FreqNegBin</span><span class="p">.</span><span class="nf">summary</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                 Claims   No. Observations:                45183
Model:                            GLM   Df Residuals:                    45161
Model Family:        NegativeBinomial   Df Model:                           21
Link Function:                    log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -2535.9
Date:                Wed, 14 Oct 2020   Deviance:                       3754.7
Time:                        21:43:23   Pearson chi2:                 1.82e+05
No. Iterations:                    21                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -0.8851      0.288     -3.069      0.002      -1.450      -0.320
Sex[T.M]       0.3927      0.163      2.403      0.016       0.072       0.713
Geog[T.2]     -0.6545      0.137     -4.778      0.000      -0.923      -0.386
Geog[T.3]     -0.9104      0.139     -6.541      0.000      -1.183      -0.638
Geog[T.4]     -1.3888      0.125    -11.100      0.000      -1.634      -1.144
Geog[T.5]     -1.5350      0.391     -3.928      0.000      -2.301      -0.769
Geog[T.6]     -1.4693      0.317     -4.635      0.000      -2.091      -0.848
Geog[T.7]    -21.1594   1.13e+04     -0.002      0.999   -2.22e+04    2.22e+04
EV[T.2]        0.0957      0.240      0.399      0.690      -0.375       0.566
EV[T.3]       -0.4359      0.202     -2.155      0.031      -0.832      -0.039
EV[T.4]       -0.3671      0.217     -1.690      0.091      -0.793       0.059
EV[T.5]       -0.0319      0.207     -0.154      0.877      -0.437       0.373
EV[T.6]        0.4212      0.205      2.054      0.040       0.019       0.823
EV[T.7]        0.3309      0.486      0.681      0.496      -0.622       1.283
NCD[T.2]      -0.1456      0.183     -0.795      0.427      -0.505       0.214
NCD[T.3]       0.0171      0.194      0.089      0.929      -0.362       0.397
NCD[T.4]       0.2965      0.186      1.591      0.112      -0.069       0.662
NCD[T.5]      -0.0509      0.217     -0.234      0.815      -0.477       0.375
NCD[T.6]       0.1034      0.208      0.498      0.618      -0.303       0.510
NCD[T.7]       0.1871      0.139      1.343      0.179      -0.086       0.460
Age           -0.0581      0.004    -13.509      0.000      -0.067      -0.050
VehAge        -0.0766      0.008     -9.730      0.000      -0.092      -0.061
==============================================================================
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig21_2.png" alt="png" /></p><p><strong><em>Binomial Model Coefficients and Logits Log-Odds, Odds and Probabilties</em></strong></p><ul><li>https://sebastiansauer.github.io/convert_logit2prob/</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">FreqBinom</span><span class="p">.</span><span class="nf">summary</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                  Claim   No. Observations:                45183
Model:                            GLM   Df Residuals:                 45690.29
Model Family:                Binomial   Df Model:                           21
Link Function:                  logit   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -3504.3
Date:                Wed, 14 Oct 2020   Deviance:                       7008.7
Time:                        21:43:23   Pearson chi2:                 4.72e+04
No. Iterations:                    24                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -2.7911      0.289     -9.672      0.000      -3.357      -2.225
Sex[T.M]       0.7379      0.153      4.832      0.000       0.439       1.037
Geog[T.2]     -0.4605      0.141     -3.265      0.001      -0.737      -0.184
Geog[T.3]     -0.6028      0.140     -4.320      0.000      -0.876      -0.329
Geog[T.4]     -0.1851      0.111     -1.668      0.095      -0.403       0.032
Geog[T.5]     -1.8854      0.514     -3.667      0.000      -2.893      -0.878
Geog[T.6]     -2.0365      0.456     -4.469      0.000      -2.930      -1.143
Geog[T.7]    -21.7246   1.56e+04     -0.001      0.999   -3.07e+04    3.06e+04
EV[T.2]       -0.0613      0.261     -0.234      0.815      -0.574       0.451
EV[T.3]        0.3441      0.198      1.734      0.083      -0.045       0.733
EV[T.4]       -0.5492      0.226     -2.426      0.015      -0.993      -0.105
EV[T.5]        0.2531      0.204      1.238      0.216      -0.147       0.654
EV[T.6]        0.3888      0.207      1.882      0.060      -0.016       0.794
EV[T.7]       -1.5831      1.025     -1.544      0.123      -3.593       0.427
NCD[T.2]      -0.3731      0.198     -1.887      0.059      -0.761       0.015
NCD[T.3]      -0.0929      0.203     -0.458      0.647      -0.490       0.305
NCD[T.4]       0.0394      0.206      0.191      0.849      -0.365       0.443
NCD[T.5]      -0.7865      0.295     -2.671      0.008      -1.364      -0.209
NCD[T.6]      -0.6098      0.273     -2.230      0.026      -1.146      -0.074
NCD[T.7]       1.0612      0.123      8.654      0.000       0.821       1.302
Age           -0.0384      0.003    -11.086      0.000      -0.045      -0.032
VehAge        -0.0705      0.006    -11.589      0.000      -0.082      -0.059
==============================================================================
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c1"># Example conversions from logits to probabilities
</span><span class="n">const</span> <span class="o">=</span> <span class="n">FreqBinom</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">odds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">const</span><span class="p">)</span>
<span class="n">probability</span> <span class="o">=</span> <span class="n">odds</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">odds</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Intercept: p = </span><span class="si">{</span><span class="n">probability</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">const</span><span class="o">+</span><span class="n">FreqBinom</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">const</span><span class="o">+</span><span class="n">FreqBinom</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Intercept + Male: p = </span><span class="si">{</span><span class="n">_</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">_</span><span class="o">-</span><span class="n">probability</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Intercept: p = 0.058
Intercept + Male: p = 0.114 (0.056)
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig25_1.png" alt="png" /></p><h3 id="prediction">Prediction</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fnb</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FreqNegBin</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">exog</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="n">offset</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">PYrs</span><span class="sh">'</span><span class="p">]))</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fpo</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FreqPoisson</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">exog</span><span class="o">=</span><span class="n">test</span><span class="p">,</span><span class="n">offset</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">PYrs</span><span class="sh">'</span><span class="p">]))</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fbi</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FreqBinom</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">exog</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mf">3.3</span><span class="p">),</span><span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fpo</span><span class="sh">'</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Poisson</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fnb</span><span class="sh">'</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">NegBinomial</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Fbi</span><span class="sh">'</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Binomial</span><span class="sh">'</span><span class="p">)</span>
<span class="n">test</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>Sex<th>Geog<th>EV<th>VehAge<th>NCD<th>PYrs<th>Claims<th>Severity<th>Claim<th>SeverityAvg<th>Fnb<th>Fpo<th>Fbi<tbody><tr><td>63584<td>69.0<td>M<td>4<td>1<td>5<td>3<td>0.361644<td>0<td>0.0<td>0<td>0.0<td>0.000694<td>0.000690<td>0.004815<tr><td>2446<td>21.0<td>M<td>4<td>5<td>8<td>3<td>0.767123<td>0<td>0.0<td>0<td>0.0<td>0.018421<td>0.018198<td>0.030839<tr><td>63505<td>69.0<td>M<td>1<td>1<td>11<td>7<td>0.665753<td>0<td>0.0<td>0<td>0.0<td>0.003833<td>0.003781<td>0.011952<tr><td>7309<td>25.0<td>M<td>3<td>5<td>1<td>6<td>0.263014<td>0<td>0.0<td>0<td>0.0<td>0.015058<td>0.014718<td>0.017250<tr><td>29573<td>42.0<td>M<td>6<td>6<td>7<td>7<td>0.257534<td>0<td>0.0<td>0<td>0.0<td>0.003391<td>0.003337<td>0.008624</table></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig27_1.png" alt="png" /></p><p>Looking at the model summaries, the histograms and results the of predicted values on the test, we see that each model weights covariates similarly and produces similar scores on the test data. <strong><em>Again note</em></strong> that the $Binomial$ model was only used to demonstrate its similarity in this case, but this may not hold for other data.</p><h3 id="claim-severity"><em>Claim Severity</em></h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c1"># including PYrs as parameter commented out in glm()
</span><span class="n">expr</span> <span class="o">=</span> <span class="sh">"</span><span class="s">SeverityAvg ~ Age + Sex + Geog + EV + VehAge + NCD</span><span class="sh">"</span>

<span class="c1">### Estimate severity using GLM-gamma with default inverse-power link
</span><span class="n">SevGamma</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">expr</span><span class="p">,</span>
              <span class="n">data</span><span class="o">=</span><span class="n">train_severity</span><span class="p">,</span>
              <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">inverse_power</span><span class="p">())).</span><span class="nf">fit</span><span class="p">()</span>
</pre></table></code></div></div><p>Ignore the warning for now we will come back to that.</p><p>After fitting a GLM-Gamma, how do we find the Gamma shape (<em>a</em>) and scale (<em>b</em>) parameters of predictions for <em>Xi</em>?</p><p>“<em>Regression with the gamma model is going to use input variables Xi and coefficients to make a pre-diction about the mean of yi, but in actuality we are really focused on the scale parameter βi. This is so because we assume that αi is the same for all observations, and so variation from case to case in μi=βiα is due simply to variation in βi.</em>” <a href="https://pj.freefaculty.org/guides/stat/Regression-GLM/Gamma/GammaGLM-01.pdf">technical overview of gamma glm</a></p><ul><li><a href="https://pj.freefaculty.org/guides/stat/Distributions/DistributionWriteups/Gamma/Gamma-02.pdf">gamma handout</a><li><a href="http://people.stat.sfu.ca/~raltman/stat402/402L26.pdf">Gamma Choice of link function</a><li><a href="https://stat.ethz.ch/pipermail/r-help/2011-July/283736.html">exmaple finding scale in R</a><li><a href="https://stats.stackexchange.com/questions/247624/dispersion-parameter-for-gamma-family">generalized linear model - Dispersion parameter for Gamma family - Cross Validated</a><li><a href="https://stackoverflow.com/questions/60215085/calculating-scale-dispersion-of-gamma-glm-using-statsmodels">Pdummy_xyhon: Calculating scale/dispersion of Gamma GLM using statsmodels</a></ul><p><a href="https://math.stackexchange.com/questions/2873763/is-it-possible-to-determine-shape-and-scale-for-a-gamma-distribution-from-a-mean?newreg=d61b4517cd304ecca335b8e69220bf0c">Alternatively you can infer gamma parameters from CI</a></p><ul><li><a href="https://rdrr.io/cran/MASS/man/gamma.shape.glm.html">gamma.shape.glm: Estimate the Shape Parameter of the Gamma Distribution R MASS</a><li><a href="https://stats.stackexchange.com/questions/356053/the-identity-link-function-does-not-respect-the-domain-of-the-gamma-family">The identity link function does not respect the domain of the Gamma family? - Cross Validated</a></ul><p>Below I illustrate the range of predicted severity values for the intercept and each level in Geography.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="c1"># shape is
</span><span class="n">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">scale</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Shape: </span><span class="si">{</span><span class="n">shape</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># intercept 
</span><span class="n">constant</span><span class="p">,</span><span class="n">intercept</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">scale</span><span class="o">/</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Intercept: </span><span class="si">{</span><span class="n">intercept</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># predicted mean G(Yi) is exp(Bo + Bi*Xi..)
</span><span class="n">geogs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">scale</span><span class="o">/</span><span class="p">(</span><span class="n">constant</span><span class="o">+</span><span class="n">c</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">)</span> <span class="k">if</span> <span class="sh">'</span><span class="s">Geog</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">i</span><span class="p">]</span>

<span class="c1"># plot
</span><span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span><span class="n">x</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span><span class="n">geogs</span><span class="p">):</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span><span class="n">stat</span><span class="o">=</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">,</span><span class="n">element</span><span class="o">=</span><span class="sh">"</span><span class="s">step</span><span class="sh">"</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">14e4</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Shape: 0.54
Intercept: 52203
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig32_1.png" alt="png" /></p><p>The GLM-Gamma model gives us a prediction of the average severity of a claim should one occur.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">test_severity</span><span class="p">[</span><span class="sh">'</span><span class="s">Giv</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">exog</span><span class="o">=</span><span class="n">test_severity</span><span class="p">)</span>
<span class="n">test_severity</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>Sex<th>Geog<th>EV<th>VehAge<th>NCD<th>PYrs<th>Claims<th>Severity<th>Claim<th>SeverityAvg<th>Giv<tbody><tr><td>35445<td>45.0<td>M<td>4<td>6<td>2<td>7<td>4.920548<td>1<td>2480.0<td>1<td>2480.0<td>28728.757724<tr><td>9653<td>26.0<td>M<td>6<td>6<td>9<td>5<td>0.589041<td>1<td>46000.0<td>1<td>46000.0<td>21782.480267<tr><td>2039<td>21.0<td>M<td>2<td>2<td>19<td>1<td>0.432877<td>1<td>11110.0<td>1<td>11110.0<td>11537.649676</table></div><p>Now, remember the error we got using the inverse-power link function. The warning is fairly self explanatory “the inverse_power link function does not respect the domain of the Gamma family”. Oddly this is a design feature of Statsmodels at the <a href="https://github.com/statsmodels/statsmodels/issues/3316#issuecomment-266453597">time of writing</a>. Rather it is better to use the log link function to ensure all predicted values are &gt; 0.</p><p><strong><em>GLM-Gamma log link</em></strong></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c1"># formula
</span><span class="n">expr</span> <span class="o">=</span> <span class="sh">"</span><span class="s">SeverityAvg ~ Age + Sex + Geog + EV + VehAge + NCD</span><span class="sh">"</span>

<span class="c1">### Estimate severity using GLM-gamma with default log link
</span><span class="n">SevGamma</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">expr</span><span class="p">,</span>
                   <span class="n">data</span><span class="o">=</span><span class="n">train_severity</span><span class="p">,</span>
                   <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">log</span><span class="p">())).</span><span class="nf">fit</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="c1"># dispersion aka rate
</span><span class="n">dispersion</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="n">scale</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Dispersion: </span><span class="si">{</span><span class="n">dispersion</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># shape is 1/dispersion
</span><span class="n">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">dispersion</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Shape: </span><span class="si">{</span><span class="n">shape</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># intercept
</span><span class="n">constant</span><span class="p">,</span><span class="n">intercept</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Intercept: </span><span class="si">{</span><span class="n">intercept</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># predicted mean G(Yi) is exp(Bo + Bi*Xi..)
# tuple(name,Yi,scale)
</span><span class="n">geogs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span>
          <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">constant</span><span class="o">+</span><span class="n">c</span><span class="p">),</span>
          <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">constant</span><span class="o">+</span><span class="n">c</span><span class="p">)</span><span class="o">*</span><span class="n">dispersion</span><span class="p">)</span>
         <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">index</span><span class="p">,</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">)</span> <span class="k">if</span> <span class="sh">'</span><span class="s">Geog</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">i</span><span class="p">]</span>

<span class="c1"># plot
</span><span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span><span class="n">x</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(),</span><span class="n">geogs</span><span class="p">):</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span><span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Dispersion: 2.0528
Shape: 0.4872
Intercept: 69330.81
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig37_1.png" alt="png" /></p><p>Statsmodels uses patsy design matrices behind the scenes. We can apply the design matrix to calculate the distribution parameters for both the frequency and severity models, and for any data set. Train, test, synthetic data and portfolios. You name it.</p><p>This is an incredibly powerfull approach as it enables the development of highly parameterised Monte Carlo and risk simulation models.I will walk the steps using pandas dataframes so that it is clear:</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="c1"># 1. Define a dummy model for your data and using the same formula and settings defined earlier.
</span><span class="n">dummy_</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">expr</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">test_severity</span><span class="p">,</span><span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="nc">Gamma</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="n">sm</span><span class="p">.</span><span class="n">families</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="nf">log</span><span class="p">()))</span>

<span class="c1"># 2. we can then access the desing matrix. 
# Which is simply the data values, but also handling the intercept and reference categories.
</span><span class="n">a</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">dummy_</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">exog</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">dummy_</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">param_names</span><span class="p">)</span>

<span class="c1"># 3. Retrieve and transpose the trained model coefficients
</span><span class="n">b</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">).</span><span class="n">T</span>

<span class="c1"># 4. And multiply together
# but this only works if indexes are equal
</span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 5. It is much cleaner to use arrays. 
# et voila
</span><span class="n">c</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">dummy_</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">exog</span> <span class="o">*</span> <span class="n">SevGamma</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">values</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">dummy_</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">param_names</span><span class="p">)</span>
</pre></table></code></div></div><p>We can then use the coefficients to estimate and plot the values and samples of each row, or the entire dataset.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">dispersion</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="n">scale</span>
<span class="n">shape</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">dispersion</span>

<span class="n">num</span><span class="o">=</span><span class="mi">5</span>
<span class="n">fig</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span><span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">pred</span><span class="p">,</span><span class="n">ax</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">index</span><span class="p">[:</span><span class="n">num</span><span class="p">],</span><span class="n">SevGamma</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_severity</span><span class="p">)[:</span><span class="n">num</span><span class="p">],</span><span class="n">axs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()):</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">loc</span><span class="p">[[</span><span class="n">i</span><span class="p">]].</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="n">dispersion</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">i</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span><span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Sample Mu </span><span class="si">{</span><span class="n">sample</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">Predicted Mu </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig41_0.png" alt="png" /></p><h1 id="putting-it-all-together-frequency-severity-model">Putting it all together: Frequency-Severity model</h1><p><strong><em>Portfolio price</em></strong></p><p>Given that this is motor insurance, lets assume a thin margin for %0.05</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="c1"># make a dummy portfolio and make predictions
</span><span class="n">portfolio</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_frq</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">FreqBinom</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">portfolio</span><span class="p">)</span>
<span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">expected_sev</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SevGamma</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">portfolio</span><span class="p">)</span>

<span class="c1"># expected annual loss
</span><span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_exp_loss</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_frq</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">expected_sev</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># set pricing ratio
</span><span class="n">tolerable_loss</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">pricing_ratio</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">tolerable_loss</span>
<span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_tech_premium</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_exp_loss</span><span class="sh">'</span><span class="p">]</span><span class="o">/</span><span class="n">pricing_ratio</span>
<span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_tech_premium</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">Severity</span><span class="sh">'</span><span class="p">]</span>
<span class="n">portfolio</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>expected_sev<th>annual_exp_loss<th>annual_tech_premium<th>result<tbody><tr><td>0<td>27818.169806<td>277.316838<td>291.912461<td>291.912461<tr><td>1<td>21753.203517<td>300.218299<td>316.019262<td>316.019262<tr><td>2<td>18524.970346<td>298.920877<td>314.653555<td>314.653555</table></div><p>This summary illustrates the:</p><ul><li>observed Claims and Losses (Severity)<li>the predicted frq, losses, and expected-losses<li>the technical premium<li>the profit loss result (calculated on full Severity rather than SeverityAvg)</ul><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Claim<th>Severity<th>annual_frq<th>expected_sev<th>annual_exp_loss<th>annual_tech_premium<th>result<tbody><tr><td>Summary<td>201.0<td>5377478.0<td>249.038867<td>4.054346e+08<td>5.764319e+06<td>6.067705e+06<td>690226.503245</table></div><p>Now we can build a Monte Carlo simulation to:</p><ul><li>provide a more robust estimate of our expected profit / loss<li>sample the parameter space to gauge the variance and uncertainty in our model and assumptions<li>calculate metrics for the AAL, AEP, and AXS loss and return</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="c1"># simulate portfolio
</span><span class="n">simulation</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="n">frq</span> <span class="o">=</span> <span class="nf">list</span><span class="p">()</span>
<span class="n">sev</span> <span class="o">=</span> <span class="nf">list</span><span class="p">()</span>
<span class="n">N</span><span class="o">=</span><span class="mi">999</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">N</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="sh">'</span><span class="se">\r</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">frq</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_frq</span><span class="sh">'</span><span class="p">]))</span>
    <span class="n">sev</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">gamma_shape</span><span class="sh">'</span><span class="p">],</span><span class="n">scale</span><span class="o">=</span><span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">gamma_scale</span><span class="sh">'</span><span class="p">]))</span>

<span class="c1"># calculate Frq * Sev
</span><span class="n">frq_sev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">sev</span><span class="p">)</span>
<span class="c1"># summarise the simulations
</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">iteration</span><span class="sh">'</span><span class="p">:</span><span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">),</span>
                                  <span class="sh">'</span><span class="s">claim_num</span><span class="sh">'</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span><span class="c1"># num claims
</span>                                  <span class="sh">'</span><span class="s">loss_min</span><span class="sh">'</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq_sev</span><span class="p">).</span><span class="nf">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># min claim
</span>                                  <span class="sh">'</span><span class="s">loss_sum</span><span class="sh">'</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq_sev</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># total
</span>                                  <span class="sh">'</span><span class="s">loss_max</span><span class="sh">'</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq_sev</span><span class="p">).</span><span class="nf">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># max claim
</span>                                  <span class="sh">'</span><span class="s">loss_avg</span><span class="sh">'</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">frq_sev</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                              <span class="p">})</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>998/999
</pre></table></code></div></div><p>Calculate the Annual Exceedence Probability</p><ul><li>https://sciencing.com/calculate-exceedance-probability-5365868.html<li>https://serc.carleton.edu/quantskills/methods/quantlit/RInt.html<li>https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/floods-return-period-and-probability/</ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">exceedance_prob</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">feature</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
    <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
    <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">Rank</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">].</span><span class="nf">rank</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="n">ascending</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">dense</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">RI</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="mf">1.0</span><span class="p">)</span><span class="o">/</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">Rank</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">EP</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">RI</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">data</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">([</span><span class="sa">f</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="n">ascending</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">data</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="c1"># profit loss based on technical premium
</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">technical_premium</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">portfolio</span><span class="p">[</span><span class="sh">'</span><span class="s">annual_tech_premium</span><span class="sh">'</span><span class="p">].</span><span class="nf">sum</span><span class="p">()</span>
<span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">technical_premium</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">loss_sum</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># recurrence intervals of each measure
</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_sum</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">exceedance_prob</span><span class="p">(</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">],</span><span class="sh">'</span><span class="s">loss_sum</span><span class="sh">'</span><span class="p">)</span>
<span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_max</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">exceedance_prob</span><span class="p">(</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">],</span><span class="sh">'</span><span class="s">loss_max</span><span class="sh">'</span><span class="p">)</span>
<span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">exceedance_prob</span><span class="p">(</span><span class="n">simulation</span><span class="p">[</span><span class="sh">'</span><span class="s">sim</span><span class="sh">'</span><span class="p">],</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><p>This illustrates the profit and loss scenarios for our pricing strategy across $N$ iterations.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig57_0.png" alt="png" /></p><p>And more intuitive EP curves.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/images/2020-05-17-glm-fig59_0.png" alt="png" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/blog-post/'>blog-post</a>, <a href='/categories/data-analysis/'>data-analysis</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/glm/" class="post-tag no-text-decoration" >glm</a> <a href="/tags/insurance/" class="post-tag no-text-decoration" >insurance</a> <a href="/tags/monte-carlo/" class="post-tag no-text-decoration" >monte carlo</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=A deep dive on GLM's in frequency severity models - Ben Postance&url=https://bpostance.github.io/posts/glm-deep-dive/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=A deep dive on GLM's in frequency severity models - Ben Postance&u=https://bpostance.github.io/posts/glm-deep-dive/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=A deep dive on GLM's in frequency severity models - Ben Postance&url=https://bpostance.github.io/posts/glm-deep-dive/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/building-ai-enterprise/">How to build an Advanced Analytics function</a><li><a href="/posts/multi-tasking-in-python/">Multi-tasking in Python</a><li><a href="/posts/airflow-taskflow/">Writing Pythonic Airflow DAGs with the TaskFlow API</a><li><a href="/posts/finCEN/">The finCEN files: Uncovering money laundering patterns in the global banking network</a><li><a href="/posts/working-with-MODIS-data/">Geospatial Analysis: Working with MODIS data</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/bayes-theory/">bayes-theory</a> <a class="post-tag" href="/tags/bayesian-inference/">bayesian-inference</a> <a class="post-tag" href="/tags/data-mining/">data-mining</a> <a class="post-tag" href="/tags/monte-carlo/">monte carlo</a> <a class="post-tag" href="/tags/classification/">classification</a> <a class="post-tag" href="/tags/clustering/">clustering</a> <a class="post-tag" href="/tags/data-cleaning/">data-cleaning</a> <a class="post-tag" href="/tags/decomposition/">decomposition</a> <a class="post-tag" href="/tags/dimension-reduction/">dimension-reduction</a> <a class="post-tag" href="/tags/geospatial-analysis/">geospatial-analysis</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/introduction-to-bayesian-inference/"><div class="card-body"> <span class="timeago small" > Dec 13, 2020 <i class="unloaded">2020-12-13T18:00:00+00:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Bayesian Inference by hand</h3><div class="text-muted small"><p> image source Jupyter notebook here Bayesian inference is a statistical method used to update one’s beliefs about a process or system upon observing data. It has wide reaching applications from...</p></div></div></a></div><div class="card"> <a href="/posts/pymc3-predictions/"><div class="card-body"> <span class="timeago small" > Feb 20, 2021 <i class="unloaded">2021-02-20T18:00:00+00:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Bayesian Inference with PyMC3: pt 2 making predictions</h3><div class="text-muted small"><p> Jupyter notebook here In this post I will show how Bayesian inference is applied to train a model and make predictions on out-of-sample test data. For this, we will build two models using a case s...</p></div></div></a></div><div class="card"> <a href="/posts/optimisation-monte-carlo/"><div class="card-body"> <span class="timeago small" > Aug 4, 2020 <i class="unloaded">2020-08-04T19:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Portfolio Optimisation: Monte Carlo method</h3><div class="text-muted small"><p> Jupyter notebook here Given a fixed amount of avliable resources, optimise allocation to maximise returns across a set of products with variable returns. Following the Modern Portfolio Theory m...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/clustering-mixed-type-data/" class="btn btn-outline-primary" prompt="Older"><p>A guide to clustering large datasets with mixed data-types</p></a> <a href="/posts/optimisation-monte-carlo/" class="btn btn-outline-primary" prompt="Newer"><p>Portfolio Optimisation: Monte Carlo method</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//https-bpostance-github-io.disqus.com/embed.js', disqusConfig: function() { this.page.title = 'A deep dive on GLM's in frequency severity models'; this.page.url = 'https://bpostance.github.io/posts/glm-deep-dive/'; this.page.identifier = '/posts/glm-deep-dive/'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/username">BenPostance</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/bayes-theory/">bayes theory</a> <a class="post-tag" href="/tags/bayesian-inference/">bayesian inference</a> <a class="post-tag" href="/tags/data-mining/">data mining</a> <a class="post-tag" href="/tags/monte-carlo/">monte carlo</a> <a class="post-tag" href="/tags/classification/">classification</a> <a class="post-tag" href="/tags/clustering/">clustering</a> <a class="post-tag" href="/tags/data-cleaning/">data cleaning</a> <a class="post-tag" href="/tags/decomposition/">decomposition</a> <a class="post-tag" href="/tags/dimension-reduction/">dimension reduction</a> <a class="post-tag" href="/tags/geospatial-analysis/">geospatial analysis</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#top" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://bpostance.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
